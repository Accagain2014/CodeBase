## 探讨LR的各种优化算法
## SGD/OGD
## 梯度截断
## FOBOS
## RDA
> [Dual Averaging Methods for Regularized Stochastic Learning and Online Optimization](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/xiao10JMLR.pdf)
<br> 2010, Microsoft.
<br> 
## FTRL
> [Ad Click Prediction: a View from the Trenches](../readings/ctr/2013%20KDD%20Ad%20Click%20Prediction-%20a%20View%20from%20the%20Trenches.pdf)



> [Efficient Learning using Forward-Backward Splitting](https://stanford.edu/~jduchi/projects/DuchiSi09b.pdf)
<br> two phase.

> [Follow-the-Regularized-Leader and Mirror Descent: Equivalence Theorems and L1 Regularization](https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/37013.pdf)