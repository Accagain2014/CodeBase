## 常见问题总结

1. 类别信息为什么需要用one-hot编码？
    - 如果直接用值的话，有了序大小的概念，很多模型不适合，用ont-hot编码后，各种类别能统一处理；
    - 值的大小不能建模类别之间的关系；
    - 树模型需不需要one_hot编码？

    
2. 深度学习中为什么会产生梯度消失和梯度爆炸问题？
    - 当深度深了的话, 梯度以深度为指数的, 当底数小于1且很小的话, 会有梯度消失的问题; 当底数大于1时, 会有梯度爆炸的问题


3. 怎样处理特征值是连续的情况, 见参考[1].
    - **Binning The Variable**. 把连续值分组，在组内统计，开始粒度小，从而发现一些模式；
    - **Normalization**. 求出正态分布参数(均值和方差)，然后计算Z-score, $ z = \frac{x - \mu }{ \sigma } $, 引入了序的概念；
    - **Transformations for Skewed Distribution:**. 原始数据倾斜比较大，降低了低频值影响。要注意离群点。Log, sqrt, exp, Box-cox, power etc.
    - **Use of Business Logic**. 从业务的角度理解数据, think out of data；
    - **New Features**. 从业务角度理解，特征计算得到新的特征的意思；
    - **Treating Outliers**. 离群数据处理; 移除最大的1%和最小的1%; 
    - **Principal Component Analysis**. 得到重要的特征，进行处理;
    - **Feature Hashing**.
    

4. 怎样处理特征值是离散的情况, 见参考[2].
    - **Label Encoder**. 给类别标号;
    - **Convert numeric bins to number**. 直接给每个桶标号; 用每个桶的平均值代替; 每个桶的最大值和最小值代替;
    - **One-hot编码**.
    

5. 怎样处理特征值是有序的情况？
    - 比如评分。
    - 

6. 怎么理解极大似然估计？
    - a

7. FTLR

8. log_loss
    - log_loss = -(ylog(y_p) + (1-y)log(1-y_p))(离散)
    - 实际上是离散的交叉熵, 衡量两个分布的


##### 参考
[1]  [8 Ways to deal with Continuous Variables in Predictive Modeling](https://www.analyticsvidhya.com/blog/2015/11/8-ways-deal-continuous-variables-predictive-modeling/)
<br> 
[2]  [Simple Methods to deal with Categorical Variables in Predictive Modeling](https://www.analyticsvidhya.com/blog/2015/11/easy-methods-deal-categorical-variables-predictive-modeling/) 