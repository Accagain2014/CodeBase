## Cos相似性
- Sc(A, B) = cos similarity = cos() = A dot B / |A| / |B|

## Cos距离
- Dc(A, B) = 1 - Sc(A, B) = cos distance = 1 - cos()
- 正向空间

## Jaccard相似性
- Js(A, B) = | A & B | / | A | B|

## Jaccard距离
- Jd(A, B) = 1 - Js(A, B) = 1 - | A & B| / | A | B |

## AUC
- 深入理解
    - 带着一种阈值的观点去理解(FPR，TPR)曲线，当分类阈值为0时，所有的都是对的，对应于(1, 1), 当阈值最大时，所有的都预测为阴性，对应于(0, 0)
    - [理解](https://www.zhihu.com/question/39840928)
    - 根据thredholds得到(FPR, TPR)，并绘制出曲线，得到最终的AUC
    - 用看病的例子，阴阳性，
    - 假阴性FN： 预测没病，实际有病。漏报。
    - 假阳性FP： 预测有病，实际没病。误报。
    - 真阴性TN： 预测没病，实际没病。
    - 真阳性TP： 预测有病，实际有病。
    - FPR = FP / (FP + TN) 假阳率，预测有病，实际没病，占实际没病的比例；预测为正但实际为负的样本占所有负例样本的比例；
    - TPR = TP / (TP + FN) 真阳率，预测有病，实际有病，占实际有病的比例，预测为正且实际为正的样本占所有正例样本的比例；
    - 阴阳实际的情况，真假预测的情况，预测的在前，真实的在后。
    - [实现](../system/tools/ml_metrics.py)
    - 本质含义：我们希望分类器达到的效果是：对于真实类别为1的样本，分类器预测为1的概率（即TPRate），要大于真实类别为0而预测类别为1的概率（即FPRate），这样的ROC曲线是在y=x之上的。
    - AUC的计算方法同时考虑了分类器对于正例和负例的分类能力，在样本不平衡的情况下，依然能够对分类器作出合理的评价。
    - 从Mann–Whitney+U+statistic的角度来解释，AUC就是从所有1样本中随机选取一个样本，+从所有0样本中随机选取一个样本，然后根据你的分类器对两个随机样本进行预测，把1样本预测为1的概率为p1，把0样本预测为1的概率为p0，p1>p0的概率就等于AUC。所以AUC反应的是分类器对样本的排序能力。&oq=从Mann–Whitney+U+statistic的角度来解释，AUC就是从所有1样本中随机选取一个样本，+从所有0样本中随机选取一个样本，然后根据你的分类器对两个随机样本进行预测，把1样本预测为1的概率为p1，把0样本预测为1的概率为p0，p1>p0的概率就等于AUC。所以AUC反应的是分类器对样本的排序能力。
    -  The AUC value is equivalent to the probability that a randomly chosen positive example is ranked higher than a randomly chosen negative example.
    - AUC是指 随机给定一个正样本和一个负样本，分类器输出该正样本为正的那个概率值 比 分类器输出该负样本为正的那个概率值 要大的可能性。
    ![](../images/AUC.png)
    

