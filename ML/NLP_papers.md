## A collection of popular NLP papers.
----
- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1810.04805.pdf)
    - 2018. Google.
    - (tensorflow version)[https://github.com/google-research/bert]

- [GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding](https://www.nyu.edu/projects/bowman/glue.pdf)

- [Improving Language Understanding by Generative Pre-Training](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf)
    - OpenAI GPT (Radford et al., 2018)
    
- [Attention Is All You Need](https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf)
    - 2017 BERT之前， Transformer
    - [The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html)
    - [tensor2tensor library](https://github.com/tensorflow/tensor2tensor)
    
## Terms
- NLI: Natural Language Inference
- QA:  Question Answering
- GLUE: General Language Understanding Evaluation benchmark


 